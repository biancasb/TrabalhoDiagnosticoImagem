# -*- coding: utf-8 -*-
"""TrabalhoDPI-BiancaSiega.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HD8bU2SzBz0-2Q6eY3kqi1UP8bpzCIrt

# <font color='mediumpurple'>Diagnóstico por Imagem</font>

#### Informática Biomédica
#### Universidade Federal de Ciências da Saúde de Porto Alegre - UFCSPA  

Bianca Siega Bernardi
"""

import numpy as np
import pandas as pd

from tqdm import tqdm

import matplotlib.pyplot as plt
import cv2
import os
import shutil
import itertools
import imutils

from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import plotly.graph_objects as go

from plotly.offline import init_notebook_mode, iplot
from plotly import tools

from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras import layers
from keras.models import Model, Sequential
from keras.optimizers import Adam, RMSprop
from keras.callbacks import EarlyStopping

init_notebook_mode(connected=True)

"""# Organização do Dataset e ajustes necessários"""

import kagglehub

path = kagglehub.dataset_download("alfageme/dermatologic-ultrasound-images")
ings = path + '/images/bw'
csv = pd.read_csv(path + '/201database.csv', header='infer')
csv.columns = csv.columns.str.strip()

# Criação das pastas
if not os.path.exists("CLASS"):
    os.makedirs("CLASS")
if not os.path.exists("BW"):
    os.makedirs("BW")
if not os.path.exists("DOPPLER"):
    os.makedirs("DOPPLER")

dop = "doppler"

# Inserção das imagens nos diretórios correspondentes
for arquivo in os.listdir(ings):
  if dop in arquivo:
    shutil.copy(ings + "/" + arquivo, "DOPPLER")
  else:
    shutil.copy(ings + "/" + arquivo, "BW")

print(csv)

# Identificar e remover as imagens que são doppler
bw = '/content/BW'

# Define as faixas de valores HSV para cada cor
color_ranges = {
    'vermelho': ([0, 120, 70], [10, 255, 255]),
    'amarelo': ([20, 100, 100], [30, 255, 255]),
    'azul': ([100, 100, 100], [130, 255, 255]),
    'verde': ([40, 40, 40], [80, 255, 255])
}

for arquivo in os.listdir(bw):
    img = cv2.imread(bw + '/' + arquivo)
    if img is not None:  # Verifica se a imagem foi carregada com sucesso
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

        is_colored = False
        for color_name, (lower, upper) in color_ranges.items():
            # Cria a máscara para a cor especificada
            mask = cv2.inRange(hsv, np.array(lower), np.array(upper))

            # Verifica se a máscara possui pixels detectados
            if np.any(mask > 0):
                is_colored = True
                print(f'Imagem {arquivo} contém {color_name} e será removida.')
                break

        if is_colored:
            os.remove(bw + '/' + arquivo)
            print(f'Deletando {arquivo}')

    else:
        print(f'Erro ao carregar a imagem {arquivo}')

# Droppar a coluna freq;;;;;;

csv = csv.drop(columns=['freq;;;;;;'])
csv

# Primeiro ajustar as nomeclaturas na coluna dx

resultados_dx = csv['dx']
print(resultados_dx)

# Pegar os resultados da coluna dx e listar
resultados_dx = csv['dx'].to_list()
print(resultados_dx)

# Pega todos os valores unicos
print(csv['dx'].unique())

# Normalizar espaços em branco
csv['dx'] = csv['dx'].str.strip()

# Corrigir variações específicas de nomes
csv['dx'] = csv['dx'].str.replace('Schwanoma', 'SCHWANNOMA')
csv['dx'] = csv['dx'].replace({'LEYOMIOMA': 'LEIOMYOMA', 'LEIOMIOMA':'LEIOMYOMA'}, regex=True)
csv['dx'] = csv['dx'].str.replace('VENOUS MALFORMATION', 'VASCULAR MALFORMATION')
csv['dx'] = csv['dx'].str.replace('SEBK', 'SEBORRHEIC KERATOSIS')
csv['dx'] = csv['dx'].str.replace('SK', 'SEBORRHEIC KERATOSIS')
csv['dx'] = csv['dx'].str.replace('FIBROFOLLICULOMA', 'FIBROFOLICULOMA')

# Colocar todos os nomes em letras maiúsculas para padronização
csv['dx'] = csv['dx'].str.upper()

# Pega todos os valores unicos
print(csv['dx'].unique())

resultados_dx = csv['dx'].to_list()
csv

# Criar as pastas de acordo com a coluna dx dentro da CLASS

for resultado in resultados_dx:
    if not os.path.exists("CLASS/" + resultado):
        os.makedirs("CLASS/" + resultado)

# Garante que a coluna 'image_id' exista

if 'image_id' not in csv.columns:
    # Assume que os IDs das imagens podem ser extraídos dos nomes dos arquivos
    csv['image_id'] = csv['images_bw'].str.extract(r'(\d+_\w+\.jpg)')

for arquivo in os.listdir("BW"):
    # Verifica se o 'arquivo' está presente na coluna 'image_id'
    if arquivo in csv['image_id'].values:
        destination_folder = csv.loc[csv['image_id'] == arquivo, 'dx'].values[0]
        if destination_folder not in csv.columns:
            shutil.copy("BW/" + arquivo, "CLASS/" + destination_folder + "/" + arquivo)
    else:
        print(f"Aviso: {arquivo} não encontrado na coluna 'image_id' do CSV.")

import os
import shutil

# Obter uma lista de subpastas dentro da pasta "CLASS"
class_folders = [f for f in os.listdir("CLASS") if os.path.isdir(os.path.join("CLASS", f))]

# Criar um dicionário para armazenar o número de imagens em cada subpasta
folder_image_counts = {}
for folder in class_folders:
    folder_image_counts[folder] = len(os.listdir(os.path.join("CLASS", folder)))

# Ordenar as pastas pelo número de imagens em ordem decrescente
sorted_folders = sorted(folder_image_counts.items(), key=lambda item: item[1], reverse=True)

# Separar as 10 classes com mais imagens
top_10_folders = sorted_folders[:10]

# Obter a lista de pastas para manter
folders_to_keep = [folder for folder, count in top_10_folders]

# Iterar por todas as pastas e remover aquelas que não estão no top 10
for folder in class_folders:
    if folder not in folders_to_keep:
        folder_path = os.path.join("CLASS", folder)
        shutil.rmtree(folder_path)
        print(f"Pasta removida: {folder}")

# Imprimir as 10 principais classes que têm mais imagens em ordem decrescente
for folder, count in top_10_folders:
    print(f"Repositório: {folder}, Quantidade de imagens: {count}")

import os
import cv2
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Diretório base
base_dir = '/content/CLASS'

# Limite mínimo e máximo de imagens por classe
limite_minimo = 50
limite_maximo = 50

# Criar um gerador de Data Augmentation
datagen = ImageDataGenerator(
    shear_range=0.1,
    zoom_range=0.05,
    horizontal_flip=False,
    fill_mode='constant',
    rotation_range=5,
)

# Contar as imagens em cada subpasta (classe)
class_counts = {}
for subfolder in os.listdir(base_dir):
    subfolder_path = os.path.join(base_dir, subfolder)
    if os.path.isdir(subfolder_path):
        class_counts[subfolder] = len([f for f in os.listdir(subfolder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])

# Aplicar Data Augmentation para classes com menos de 50 imagens
for class_name, count in class_counts.items():
    subfolder_path = os.path.join(base_dir, class_name)
    print(f"Classe: {class_name}, Imagens atuais: {count}")

    # Ignorar classes com 48 ou mais imagens
    if count >= limite_minimo:
        print(f"Classe {class_name} já possui 50 ou mais imagens. Ignorada.")
        continue

    # Gerar novas imagens até atingir o limite mínimo (sem ultrapassar 50 imagens)
    num_to_generate = min(limite_minimo - count, limite_maximo - count)
    images = [f for f in os.listdir(subfolder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    generated = 0

    while generated < num_to_generate:
        for image_name in images:
            image_path = os.path.join(subfolder_path, image_name)

            # Ler a imagem
            img = cv2.imread(image_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = np.expand_dims(img, axis=0)  # Expandir dimensões para usar no gerador

            # Verificar se a contagem total de imagens ultrapassa o limite máximo
            current_count = len([f for f in os.listdir(subfolder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
            if current_count >= limite_maximo:
                print(f"Classe {class_name} atingiu o limite máximo de 50 imagens.")
                break

            # Gerar novas imagens
            for batch in datagen.flow(
                img,
                batch_size=1,
                save_to_dir=subfolder_path,
                save_prefix=f"aug_{os.path.splitext(image_name)[0]}",
                save_format='jpg'
            ):
                generated += 1
                if generated >= num_to_generate:
                    break

        # Verificar novamente se atingiu o limite máximo
        if len([f for f in os.listdir(subfolder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]) >= limite_maximo:
            break

        print(f"Classe {class_name}: {generated}/{num_to_generate} imagens geradas.")

print("\nData augmentation concluído. Todas as classes com menos de 48 imagens foram balanceadas sem ultrapassar 50 imagens.")

import os
import matplotlib.pyplot as plt

class_dir = '/content/CLASS/'

# Lista de subdiretórios (classes)
class_folders = [f for f in os.listdir(class_dir) if os.path.isdir(os.path.join(class_dir, f))]

# Cria um dicionário para armazenar as contagens de imagens para cada classe
image_counts = {}
for folder in class_folders:
    image_counts[folder] = len(os.listdir(os.path.join(class_dir, folder)))

# Ordena as classes com base nas contagens de imagens (opcional)
sorted_classes = sorted(image_counts.items(), key=lambda item: item[1], reverse=True)

# Extrai nomes de classes e contagens de imagens para plotagem
classes = [item[0] for item in sorted_classes]
counts = [item[1] for item in sorted_classes]

plt.figure(figsize=(12, 6))
plt.bar(classes, counts)
plt.bar(classes, counts, color='mediumpurple')
plt.xlabel("Classes")
plt.ylabel("Número de Imagens")
plt.title("Quantidade de imagens em cada subclasse")
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

"""# Separação para Treino, Teste e Validação"""

import os
import shutil
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Diretório base contendo as imagens organizadas em subpastas
base_dir = '/content/CLASS'

# Diretórios de saída para treino, teste e validação
output_dir = '/content/'
train_dir = os.path.join(output_dir, 'TRAIN')
test_dir = os.path.join(output_dir, 'TEST')
val_dir = os.path.join(output_dir, 'VAL')

# Criar os diretórios de saída
os.makedirs(train_dir, exist_ok=True)
os.makedirs(test_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)

# Proporções para a divisão
test_size = 0.2  # 20% para teste
val_size = 0.2   # 20% do conjunto restante (após separar o teste)

# Dividir os dados para cada classe (subpasta)
for class_name in os.listdir(base_dir):
    class_path = os.path.join(base_dir, class_name)
    if not os.path.isdir(class_path):
        continue

    # Obter todas as imagens da classe
    images = [os.path.join(class_path, f) for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    # Dividir os dados em treino, teste e validação
    train_val_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
    train_images, val_images = train_test_split(train_val_images, test_size=val_size, random_state=42)

    # Criar diretórios específicos para a classe
    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)

    # Mover as imagens para os diretórios apropriados
    for image in train_images:
        shutil.copy(image, os.path.join(train_dir, class_name))
    for image in test_images:
        shutil.copy(image, os.path.join(test_dir, class_name))
    for image in val_images:
        shutil.copy(image, os.path.join(val_dir, class_name))

    print(f"Classe {class_name}:")
    print(f"  Treino: {len(train_images)} imagens")
    print(f"  Teste: {len(test_images)} imagens")
    print(f"  Validação: {len(val_images)} imagens")

print("\nDivisão concluída. Os dados foram separados em treino, teste e validação respeitando os labels.")

image = []
dir = '/content/TEST/METASTASIS/'
for img in os.listdir(dir):
    image_path = os.path.join(dir, img)
    image.append(cv2.imread(image_path))
print(image[0].shape)

import os

base_dir = '/content/CLASS'

class_counts = {}

for subfolder in os.listdir(base_dir):
    subfolder_path = os.path.join(base_dir, subfolder)
    if os.path.isdir(subfolder_path):
        class_counts[subfolder] = len([f for f in os.listdir(subfolder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])

sorted_classes = sorted(class_counts.items(), key=lambda item: item[1], reverse=True)

top_10_classes = [item[0] for item in sorted_classes[:10]]

categories = top_10_classes

print(categories)

train_dir = '/content/TRAIN/'
val_dir = '/content/VAL/'
test_dir = '/content/TEST/'

x_test = []
y_test = []
x_train = []
y_train = []
x_val = []
y_val = []

image_shape = (200,200,3)

for dir in os.listdir(train_dir):
    if dir in categories:
       path = os.path.join(train_dir, dir)
       for image in tqdm(os.listdir(path), desc=f'Processing {dir}'):
          image = cv2.imread(os.path.join(path, image))
          # Redimenciona a imagem para o formato que eu quero
          image = cv2.resize(image, (image_shape[0], image_shape[1]))
          x_train.append(image)
          y_train.append(categories.index(dir))

for dir in os.listdir(test_dir):
    if dir in categories:
       path = os.path.join(test_dir, dir)
       for image in tqdm(os.listdir(path), desc=f'Processing {dir}'):
          image = cv2.imread(os.path.join(path, image))
         # Redimenciona a imagem para o formato que eu quero
          image = cv2.resize(image, (image_shape[0], image_shape[1]))
          x_test.append(image)
          y_test.append(categories.index(dir))

for dir in os.listdir(val_dir):
    if dir in categories:
       path = os.path.join(val_dir, dir)
       for image in tqdm(os.listdir(path), desc=f'Processing {dir}'):
          image = cv2.imread(os.path.join(path, image))
          # Redimenciona a imagem para o formato que eu quero
          image = cv2.resize(image, (image_shape[0], image_shape[1]))
          x_val.append(image)
          y_val.append(categories.index(dir))

x_train = np.array(x_train)
x_test = np.array(x_test)
x_val = np.array(x_val)

#Exibir formas dos arrays
print(f"x_train shape: {x_train.shape}, y_train shape: {np.array(y_train).shape}")
print(f"x_test shape: {x_test.shape}, y_test shape: {np.array(y_test).shape}")
print(f"x_val shape: {x_val.shape}, y_val shape: {np.array(y_val).shape}")

#Normalização
x_train = x_train / 255.0
x_test = x_test / 255.0
x_val = x_val / 255.0

"""# Pré treinamento - DenseNet"""

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D

#Carregar a DenseNet121 pré-treinada
base_model = DenseNet121(weights='imagenet',
                         include_top=False,
                         input_shape=(200, 200, 3))

#Congelar as camadas do modelo base
base_model.trainable = False

base_model.summary()

from tensorflow.keras.regularizers import l2

model = Sequential([
    base_model, #Transfer Learning
    GlobalAveragePooling2D(), # Reduz a dimensionalidade
    Dense(128, activation='relu', kernel_regularizer=l2(0.01)), # Camada intermediária com L2
    Dense(len(categories), activation='softmax', kernel_regularizer=l2(0.01)) # Camada de saída com L2
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

import numpy as np

x_train = np.array(x_train)
y_train = np.array(y_train)
x_val = np.array(x_val)
y_val = np.array(y_val)


history = model.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    epochs=20,
    batch_size=32
)

import matplotlib.pyplot as plt

plt.figure(figsize=(15, 5))

# Treinando e validando Valor Perda
plt.subplot(1, 2, 1)
plt.plot(history.history["loss"], label="Treinamento", color="#A78BFA")
plt.plot(history.history["val_loss"], label="Validação", color="#7851a9")
plt.xlabel("Época")
plt.ylabel("Perda")
plt.legend()

# Treinando e validando Acurácia
plt.subplot(1, 2, 2)
plt.plot(history.history["accuracy"], label="Treinamento", color="#A78BFA")
plt.plot(history.history["val_accuracy"], label="Validação", color="#7851a9")
plt.xlabel("Época")
plt.ylabel("Acurácia")
plt.legend()

plt.show()

import seaborn as sns
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

from sklearn.model_selection import train_test_split

Y_pred_prob = model.predict(x_test)

Y_pred_test = np.argmax(Y_pred_prob, axis=1)

cmat = confusion_matrix(y_test, Y_pred_test)
cm_df = pd.DataFrame(cmat)

unique_classes = np.unique(np.concatenate((y_test, Y_pred_test)))
classes = [categories[i] for i in unique_classes]

plt.figure()
ax = plt.subplot()
plt.title("Matriz Confusão")
sns.heatmap(cm_df, annot=True, cmap="Purples", fmt="d", cbar=False, xticklabels=classes, yticklabels=classes)

import os
import uuid
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix

def save_training_results(model, history, x_test, y_test, categories):
    """Salva os resultados do treinamento, incluindo gráficos, matriz de confusão (usando sns.heatmap) e modelo."""

    # Gera um nome de diretório exclusivo usando uuid
    unique_id = str(uuid.uuid4())[:8]  # Obtém os primeiros 8 caracteres para abreviar
    output_dir = os.path.join("/content", f"training_results_{unique_id}")
    os.makedirs(output_dir, exist_ok=True)  # Cria o diretório

    # Salva o modelo
    model_path = os.path.join(output_dir, "model.h5")
    model.save(model_path)
    print(f"Modelo salvo em: {model_path}")

    # Salva o gráfico de perda/acurácia de treinamento e validação
    plot_filename = os.path.join(output_dir, "training_plot.png")
    plt.figure(figsize=(15, 5))

    # Gráfico de perda de treinamento e validação
    plt.subplot(1, 2, 1)
    plt.plot(history.history["loss"], label="Treinamento", color="#A78BFA")
    plt.plot(history.history["val_loss"], label="Validação", color="#7851a9")
    plt.xlabel("Época")
    plt.ylabel("Perda")
    plt.legend()

    # Gráfico de acurácia de treinamento e validação
    plt.subplot(1, 2, 2)
    plt.plot(history.history["accuracy"], label="Treinamento", color="#A78BFA")
    plt.plot(history.history["val_accuracy"], label="Validação", color="#7851a9")
    plt.xlabel("Época")
    plt.ylabel("Acurácia")
    plt.legend()

    # Salva o gráfico
    plt.savefig(plot_filename)
    plt.show()  # Exibe o gráfico
    print(f"Gráfico de treinamento salvo em: {plot_filename}")

    # Gera e salva a matriz de confusão usando sns.heatmap
    Y_pred_prob = model.predict(x_test)
    Y_pred_test = np.argmax(Y_pred_prob, axis=1)
    cmat = confusion_matrix(y_test, Y_pred_test)


    # Obtém classes únicas de previsões e valores reais
    unique_classes = np.unique(np.concatenate((y_test, Y_pred_test)))

    # Filtra categorias para incluir apenas aquelas presentes no conjunto de teste
    filtered_categories = [categories[i] for i in unique_classes]

    cm_df = pd.DataFrame(cmat, index=filtered_categories, columns=filtered_categories)
    plt.figure(figsize=(8, 8))
    # sns.heatmap(cm_df, annot=True, cmap="Purples", fmt="d", cbar=False, square=True)
    sns.heatmap(cm_df, annot=True, cmap="Purples", fmt="d", cbar=False, xticklabels=classes, yticklabels=classes)
    plt.title("Matriz de Confusão")
    plt.xlabel("Previsões")
    plt.ylabel("Valores Reais")

    cm_filename = os.path.join(output_dir, "confusion_matrix.png")
    plt.savefig(cm_filename)
    plt.show()
    print(f"Matriz de confusão salva em: {cm_filename}")

save_training_results(model, history, x_test, y_test, categories)

save_training_results(model, history, x_test, y_test, categories)

save_training_results(model, history, x_test, y_test, categories)